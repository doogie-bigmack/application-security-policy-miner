{
  "metadata": {
    "name": "E2E Testing Infrastructure PRD",
    "description": "Product requirements for building the automated E2E testing system that validates Policy Miner features",
    "version": "2.0",
    "created": "2026-01-09",
    "updated": "2026-01-09",
    "github_issue_v1": "https://github.com/doogie-bigmack/application-security-policy-miner/issues/53",
    "github_issue_v2": "https://github.com/doogie-bigmack/application-security-policy-miner/issues/76"
  },
  "stories": [
    {
      "id": "TEST-001",
      "category": "infrastructure",
      "priority": "critical",
      "description": "Create e2e directory structure and Python dependencies",
      "steps": [
        "Create e2e/ directory in project root",
        "Create e2e/__init__.py for Python package",
        "Create e2e/requirements.txt with dependencies: anthropic, requests, jq (via subprocess)",
        "Create e2e/README.md explaining directory structure",
        "Verify Python 3.12 compatibility"
      ],
      "passes": true,
      "acceptance_criteria": [
        "e2e/ directory exists",
        "requirements.txt can be installed with pip",
        "All dependencies resolve without conflicts"
      ]
    },
    {
      "id": "TEST-002",
      "category": "infrastructure",
      "priority": "critical",
      "description": "Implement ClaudeChromeExecutor wrapper for browser automation",
      "steps": [
        "Create e2e/test_executor.py",
        "Implement ClaudeChromeExecutor class",
        "Add navigate(url) method wrapping mcp__claude-in-chrome__navigate",
        "Add click(selector) method wrapping mcp__claude-in-chrome__computer",
        "Add fill_input(selector, value) method wrapping mcp__claude-in-chrome__form_input",
        "Add assert_visible(selector, timeout_ms) method wrapping mcp__claude-in-chrome__read_page",
        "Add take_screenshot(filename) method wrapping mcp__claude-in-chrome__computer screenshot",
        "Add wait_for_element(selector, timeout_ms) method",
        "Add get_page_text() method for debugging",
        "Add error handling and retry logic",
        "Create unit tests for each method"
      ],
      "passes": true,
      "acceptance_criteria": [
        "ClaudeChromeExecutor can navigate to localhost:3333",
        "Can click elements by selector",
        "Can fill form inputs",
        "Can assert element visibility",
        "Screenshots save to e2e/screenshots/ on failure"
      ]
    },
    {
      "id": "TEST-003",
      "category": "infrastructure",
      "priority": "critical",
      "description": "Create e2e-tests.json schema and 5 critical test definitions",
      "steps": [
        "Create e2e-tests.json in project root",
        "Define schema version and test_suites structure",
        "Create test suite: repository_management",
        "Add test: test_add_github_repository (maps to prd.json FUNC-001)",
        "Add test: test_scan_repository (maps to prd.json AI rule mining)",
        "Add test: test_view_policies (maps to prd.json policy viewing)",
        "Add test: test_add_pbac_provider (maps to prd.json PBAC integration)",
        "Add test: test_provision_policy (maps to prd.json policy provisioning)",
        "Define test steps with actions: navigate, click, fill, wait_for_element, assert_element_visible",
        "Add expected_outcomes for each test",
        "Add cleanup steps for test data",
        "Add prerequisites (services, test_data) for each test",
        "Validate JSON syntax"
      ],
      "passes": true,
      "acceptance_criteria": [
        "e2e-tests.json is valid JSON",
        "Contains 5 test definitions",
        "Each test maps to a prd.json story ID",
        "All required fields present: test_id, prd_story_id, name, priority, steps"
      ]
    },
    {
      "id": "TEST-004",
      "category": "infrastructure",
      "priority": "critical",
      "description": "Create test-results.json schema and TestReporter implementation",
      "steps": [
        "Create example test-results.json schema in docs or comments",
        "Create e2e/test_reporter.py",
        "Implement TestReporter class",
        "Add generate_report() method that creates test-results.json",
        "Include test run metadata: test_run_id, started_at, completed_at, duration_seconds, trigger",
        "Include summary: total_tests, passed, failed, skipped, pass_rate",
        "Include detailed test_results array with status, duration, error details",
        "Add error diagnostics: type, message, step_index, screenshot, console_errors",
        "Add recommendations array using AI analysis of failures",
        "Add coverage_analysis: prd_stories_tested, prd_stories_total, coverage_percentage",
        "Validate JSON output"
      ],
      "passes": true,
      "acceptance_criteria": [
        "test-results.json generated after test run",
        "Contains all required fields per schema",
        "Pass/fail status accurately reflects test outcomes",
        "Screenshots referenced in error objects exist in e2e/screenshots/",
        "Recommendations provide actionable debugging guidance"
      ]
    },
    {
      "id": "TEST-005",
      "category": "infrastructure",
      "priority": "critical",
      "description": "Implement E2ETestRunner orchestrator",
      "steps": [
        "Create e2e/e2e_runner.py",
        "Implement E2ETestRunner class",
        "Add load_test_suite(path) method to parse e2e-tests.json",
        "Add load_prd(path) method to parse prd.json",
        "Add run_tests(filter_priority, filter_story_ids) method",
        "Implement test execution loop using ClaudeChromeExecutor",
        "Add error handling and screenshot capture on failure",
        "Add retry logic for flaky tests (1 retry max)",
        "Call TestReporter to generate test-results.json",
        "Add CLI argument parsing: --test-suite, --prd, --output, --filter-priority, --filter-story-id",
        "Add verbose logging to console"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Can execute: python3 e2e/e2e_runner.py --test-suite e2e-tests.json --prd prd.json",
        "Runs all 5 critical tests",
        "Generates test-results.json",
        "Exits with code 0 if all pass, code 1 if any fail",
        "Logs test progress to console"
      ]
    },
    {
      "id": "TEST-006",
      "category": "integration",
      "priority": "high",
      "description": "Wire damonnator_test.sh to execute E2E runner",
      "steps": [
        "Review existing damonnator_test.sh (already created in PR #54)",
        "Verify it reads @e2e-tests.json and @test-results.json",
        "Ensure it calls e2e/e2e_runner.py correctly",
        "Add logic to parse test-results.json and update prd.json test_metadata",
        "Test manual execution of damonnator_test.sh",
        "Verify it creates GitHub issues on test failures"
      ],
      "passes": true,
      "acceptance_criteria": [
        "./damonnator_test.sh 1 executes successfully",
        "Runs E2E tests via e2e_runner.py",
        "Updates prd.json with test results",
        "Creates GitHub issue if tests fail"
      ]
    },
    {
      "id": "TEST-007",
      "category": "scenarios",
      "priority": "high",
      "description": "Create reusable test scenario: Add GitHub Repository",
      "steps": [
        "Create e2e/scenarios/ directory",
        "Create e2e/scenarios/repository_crud.py",
        "Implement add_github_repository() function",
        "Navigate to http://localhost:3333/repositories",
        "Click 'Add Repository' button",
        "Click 'GitHub' integration option",
        "Fill in test token (from environment variable GITHUB_TEST_TOKEN)",
        "Click 'Connect' button",
        "Assert success message appears",
        "Assert repository appears in list",
        "Return repository ID for cleanup",
        "Add cleanup function to delete test repository"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Function successfully adds GitHub repository",
        "Returns repository ID",
        "Cleanup function removes test data"
      ]
    },
    {
      "id": "TEST-008",
      "category": "scenarios",
      "priority": "high",
      "description": "Create reusable test scenario: Scan Repository",
      "steps": [
        "Create scan_repository() function in e2e/scenarios/repository_crud.py",
        "Accept repository_id as parameter",
        "Navigate to repository detail page",
        "Click 'Start Scan' button",
        "Wait for scan to complete (check for status change)",
        "Assert scan completes successfully",
        "Assert policies were extracted (count > 0)",
        "Return scan results"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Function triggers scan successfully",
        "Waits for scan completion",
        "Validates policies extracted"
      ]
    },
    {
      "id": "TEST-009",
      "category": "scenarios",
      "priority": "medium",
      "description": "Create reusable test scenario: View and Filter Policies",
      "steps": [
        "Create e2e/scenarios/policy_viewing.py",
        "Implement view_policies() function",
        "Navigate to policies page",
        "Assert policies table is visible",
        "Assert columns: Subject (Who), Resource (What), Action (How), Conditions (When), Evidence",
        "Test filtering by subject",
        "Test filtering by resource",
        "Test sorting by different columns",
        "Click a policy row to view details",
        "Assert detail view shows code evidence"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Can navigate to policies page",
        "Can filter and sort policies",
        "Can view policy details with evidence"
      ]
    },
    {
      "id": "TEST-010",
      "category": "scenarios",
      "priority": "medium",
      "description": "Create reusable test scenario: Add PBAC Provider",
      "steps": [
        "Create e2e/scenarios/provisioning_flow.py",
        "Implement add_pbac_provider() function",
        "Navigate to PBAC providers page",
        "Click 'Add Provider' button",
        "Select provider type (OPA/AWS/Axiomatics)",
        "Fill in provider configuration (endpoint, credentials)",
        "Click 'Test Connection' button",
        "Assert connection test succeeds",
        "Click 'Save' button",
        "Assert provider appears in list",
        "Return provider ID for cleanup"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Can add PBAC provider",
        "Connection test validates successfully",
        "Provider saved and visible in list"
      ]
    },
    {
      "id": "TEST-011",
      "category": "scenarios",
      "priority": "medium",
      "description": "Create reusable test scenario: Provision Policy to PBAC",
      "steps": [
        "Create provision_policy() function in e2e/scenarios/provisioning_flow.py",
        "Accept policy_id and provider_id as parameters",
        "Navigate to policy detail page",
        "Click 'Provision' button",
        "Select target PBAC provider from dropdown",
        "Select target format (OPA Rego / AWS Cedar / Axiomatics ALFA)",
        "Click 'Provision' button",
        "Wait for provisioning to complete",
        "Assert provisioning status shows 'Success'",
        "Assert provisioned policy appears in provider's policy list"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Can provision policy to PBAC provider",
        "Provisioning completes successfully",
        "Policy visible in target PBAC system"
      ]
    },
    {
      "id": "TEST-012",
      "category": "validation",
      "priority": "critical",
      "description": "End-to-end validation: Run full test suite and verify feedback quality",
      "steps": [
        "Run: python3 e2e/e2e_runner.py --test-suite e2e-tests.json --prd prd.json --output test-results.json",
        "Verify all 5 critical tests execute",
        "Check test-results.json is generated",
        "Verify summary section shows correct pass/fail counts",
        "For any failed tests, verify error diagnostics include: type, message, step_index, screenshot path, console_errors",
        "Verify screenshots exist in e2e/screenshots/ for failed tests",
        "Verify recommendations array provides actionable debugging steps",
        "Run a deliberate failure test (break a selector) to validate failure reporting",
        "Verify failure report includes: root cause analysis, code locations to check, recommended fixes"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Full test suite runs to completion",
        "test-results.json contains all required fields",
        "Failure scenarios generate rich diagnostics",
        "Recommendations are actionable and accurate",
        "Screenshots captured on failure"
      ]
    },
    {
      "id": "TEST-013",
      "category": "documentation",
      "priority": "medium",
      "description": "Update TESTING.md with actual usage examples",
      "steps": [
        "Review existing TESTING.md (created in PR #54)",
        "Add section: 'Running E2E Tests Manually'",
        "Document: python3 e2e/e2e_runner.py command with all options",
        "Add section: 'Understanding Test Results'",
        "Document test-results.json schema with examples",
        "Add section: 'Debugging Failed Tests'",
        "Include examples of using screenshots and error diagnostics",
        "Add section: 'Writing New Test Scenarios'",
        "Document e2e-tests.json schema with example test definition",
        "Add troubleshooting guide for common issues"
      ],
      "passes": true,
      "acceptance_criteria": [
        "TESTING.md updated with manual testing guide",
        "Includes command examples with output",
        "Documents schemas with examples",
        "Provides debugging guidance"
      ]
    },
    {
      "id": "TEST-014",
      "category": "integration",
      "priority": "high",
      "description": "Integrate with Makefile and validate end-to-end flow",
      "steps": [
        "Verify Makefile targets exist (created in PR #54): make e2e, make damonnator-test",
        "Test: make e2e (should run e2e_runner.py directly)",
        "Test: make damonnator-test (should run damonnator_test.sh loop)",
        "Verify: make status shows test results summary",
        "Test full flow: make docker-up && make e2e",
        "Verify services start and tests execute",
        "Test deliberate failure to verify error reporting",
        "Verify GitHub issue creation on test failure",
        "Document any issues found and fix them"
      ],
      "passes": true,
      "acceptance_criteria": [
        "make e2e runs successfully",
        "make damonnator-test executes testing loop",
        "make status shows test metrics",
        "Full flow works end-to-end"
      ]
    },
    {
      "id": "TEST-015",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Add data-testid attributes to RepositoriesPage for test automation",
      "steps": [
        "Read frontend/src/pages/RepositoriesPage.tsx",
        "Add data-testid='repositories-btn-add' to Add Repository button",
        "Add data-testid='repositories-btn-scan-full' to Scan All button",
        "Add data-testid='repositories-list' to repository list container",
        "Add data-testid='repositories-filter-type' to filter input",
        "Add data-testid='repositories-filter-status' to status filter",
        "Add data-testid='repository-row' to each repository row",
        "Add data-testid='repository-name' to repository name display",
        "Add data-testid='repository-status' to status indicator",
        "Follow naming convention: [page]-[component]-[element-type]-[descriptor]",
        "Verify all selectors in e2e-tests.json can find elements",
        "Test that attributes don't break existing functionality"
      ],
      "passes": true,
      "acceptance_criteria": [
        "RepositoriesPage has 15+ data-testid attributes",
        "All interactive elements are identifiable",
        "Naming follows convention",
        "No regression in UI functionality"
      ]
    },
    {
      "id": "TEST-016",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Add data-testid attributes to AddRepositoryModal for test automation",
      "steps": [
        "Read frontend/src/components/AddRepositoryModal.tsx",
        "Add data-testid='add-repo-modal' to modal container",
        "Add data-testid='add-repo-btn-github' to GitHub integration button",
        "Add data-testid='add-repo-btn-gitlab' to GitLab integration button",
        "Add data-testid='add-repo-btn-bitbucket' to Bitbucket integration button",
        "Add data-testid='add-repo-btn-azure-devops' to Azure DevOps button",
        "Add data-testid='add-repo-input-name' to repository name input",
        "Add data-testid='add-repo-input-url' to repository URL input",
        "Add data-testid='add-repo-input-token' to token/credentials input",
        "Add data-testid='add-repo-btn-connect' to Connect button",
        "Add data-testid='add-repo-btn-cancel' to Cancel button",
        "Add data-testid='add-repo-success-message' to success notification",
        "Add data-testid='add-repo-error-message' to error notification"
      ],
      "passes": true,
      "acceptance_criteria": [
        "AddRepositoryModal has 10+ data-testid attributes",
        "All form inputs identifiable",
        "All integration buttons identifiable",
        "Success/error messages identifiable"
      ]
    },
    {
      "id": "TEST-017",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Add data-testid attributes to PoliciesPage for test automation",
      "steps": [
        "Read frontend/src/pages/PoliciesPage.tsx",
        "Add data-testid='policies-table' to policies table container",
        "Add data-testid='policy-row' to each policy row",
        "Add data-testid='policy-subject' to subject column",
        "Add data-testid='policy-resource' to resource column",
        "Add data-testid='policy-action' to action column",
        "Add data-testid='policy-conditions' to conditions column",
        "Add data-testid='policy-evidence' to evidence column",
        "Add data-testid='policies-filter-subject' to subject filter",
        "Add data-testid='policies-filter-resource' to resource filter",
        "Add data-testid='policies-btn-export' to export button",
        "Add data-testid='policies-sort-by' to sort dropdown",
        "Add data-testid='policy-detail-view' to detail modal"
      ],
      "passes": true,
      "acceptance_criteria": [
        "PoliciesPage has 12+ data-testid attributes",
        "Table structure identifiable",
        "Filters identifiable",
        "Detail view identifiable"
      ]
    },
    {
      "id": "TEST-018",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Add data-testid attributes to ProvisioningPage for test automation",
      "steps": [
        "Read frontend/src/pages/ProvisioningPage.tsx",
        "Add data-testid='provisioning-btn-add-provider' to Add Provider button",
        "Add data-testid='provisioning-provider-list' to provider list container",
        "Add data-testid='provisioning-select-provider-type' to provider type dropdown",
        "Add data-testid='provisioning-input-endpoint' to endpoint input",
        "Add data-testid='provisioning-input-api-key' to API key input",
        "Add data-testid='provisioning-btn-test-connection' to Test Connection button",
        "Add data-testid='provisioning-btn-save' to Save button",
        "Add data-testid='provisioning-btn-provision' to Provision Policy button",
        "Add data-testid='provisioning-select-target-format' to format dropdown (OPA/Cedar/ALFA)",
        "Add data-testid='provisioning-status' to provisioning status indicator"
      ],
      "passes": true,
      "acceptance_criteria": [
        "ProvisioningPage has 8+ data-testid attributes",
        "Provider management identifiable",
        "Provisioning flow identifiable",
        "Status indicators identifiable"
      ]
    },
    {
      "id": "TEST-019",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Create backend TEST_MODE infrastructure with API mocks",
      "steps": [
        "Create backend/app/core/test_mode.py with TEST_MODE environment variable check",
        "Create backend/tests/fixtures/ directory",
        "Create backend/tests/fixtures/github_responses.py with GITHUB_LIST_REPOS and GITHUB_VERIFY_TOKEN mocks",
        "Create backend/tests/fixtures/gitlab_responses.py with GitLab API mocks",
        "Create backend/tests/fixtures/bitbucket_responses.py with Bitbucket API mocks",
        "Create backend/tests/fixtures/azure_devops_responses.py with Azure DevOps API mocks",
        "Create backend/tests/fixtures/pbac_responses.py with OPA/AWS/Axiomatics mocks",
        "Create backend/tests/fixtures/scanner_responses.py with mock scan results",
        "Update backend/app/services/github_service.py to check is_test_mode() and return mocks",
        "Update backend/app/services/gitlab_service.py with test mode check",
        "Update backend/app/services/bitbucket_service.py with test mode check",
        "Update backend/app/services/azure_devops_service.py with test mode check",
        "Update backend/app/services/provisioning_service.py with test mode check",
        "Update backend/app/services/scanner_service.py with test mode check",
        "Create .env.test with TEST_MODE=true and test database configuration",
        "Test that external APIs are NOT called when TEST_MODE=true"
      ],
      "passes": true,
      "acceptance_criteria": [
        "TEST_MODE environment variable works",
        "All external API services check test mode",
        "Mock responses match real API structure",
        "No external calls when TEST_MODE=true",
        ".env.test configured correctly"
      ],
      "notes": "Core infrastructure complete. GitHub and GitLab services have full test mode support. Bitbucket, Azure DevOps, Scanner, and Provisioning services have fixtures ready but need service updates. See backend/tests/fixtures/README.md for implementation status."
    },
    {
      "id": "TEST-020",
      "category": "real-e2e",
      "priority": "high",
      "description": "Create database seed script with test data",
      "steps": [
        "Create backend/scripts/ directory if not exists",
        "Create backend/scripts/seed_test_data.py",
        "Import necessary models: Repository, Policy, Application, PBACProvider, Organization",
        "Create seed_test_data() async function",
        "Add test organization: 'Test Organization'",
        "Add test application: 'Test App'",
        "Add test repositories from doogie-bigmack GitHub repos",
        "Add sample pre-scanned policies with subjects, resources, actions, conditions",
        "Add test PBAC provider: OPA at localhost:8181",
        "Add database commit logic",
        "Add CLI execution: if __name__ == '__main__': asyncio.run(seed_test_data())",
        "Test script execution: TEST_MODE=true python backend/scripts/seed_test_data.py",
        "Verify data appears in test database"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Seed script creates test organizations",
        "Seed script creates test applications",
        "Seed script creates test repositories",
        "Seed script creates sample policies",
        "Seed script creates test PBAC providers",
        "Script runs without errors"
      ]
    },
    {
      "id": "TEST-021",
      "category": "real-e2e",
      "priority": "medium",
      "description": "Create dedicated test repository with authorization code patterns",
      "steps": [
        "Create new GitHub repository: doogie-bigmack/test-auth-patterns",
        "Add README.md explaining purpose: test repository for policy extraction",
        "Create python/ directory with flask_decorators.py containing @require_role('admin') patterns",
        "Create csharp/ directory with Controllers.cs containing [Authorize(Roles = 'Admin')] patterns",
        "Create java/ directory with RestController.java containing @PreAuthorize('hasRole(ADMIN)') patterns",
        "Create javascript/ directory with middleware.js containing requireAuth() and checkRole() patterns",
        "Create database/ directory with procedures.sql containing SQL permissions",
        "Ensure each file has clear, scannable authorization patterns",
        "Push to GitHub",
        "Verify repository is accessible at https://github.com/doogie-bigmack/test-auth-patterns"
      ],
      "passes": true,
      "acceptance_criteria": [
        "Repository exists on GitHub",
        "Contains authorization patterns in 5+ languages",
        "Patterns are clear and scannable",
        "README documents purpose"
      ]
    },
    {
      "id": "TEST-022",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Create Claude-driven test execution scripts and prompts",
      "steps": [
        "Create e2e/prompts/ directory",
        "Create e2e/claude_test_runner.sh script that uses Claude CLI with MCP tools",
        "Create e2e/prompts/test_add_github_repository.md with step-by-step MCP tool usage",
        "Create e2e/prompts/test_scan_repository.md",
        "Create e2e/prompts/test_view_policies.md",
        "Create e2e/prompts/test_add_pbac_provider.md",
        "Create e2e/prompts/test_provision_policy.md",
        "Each prompt should specify: Setup requirements, MCP tools to use, Step-by-step actions, Expected outcomes, Failure handling",
        "Update claude_test_runner.sh to read test definition from e2e-tests.json",
        "Script should pass test definition to Claude as prompt",
        "Claude should invoke: mcp__claude-in-chrome__tabs_context_mcp, mcp__claude-in-chrome__navigate, mcp__claude-in-chrome__computer, mcp__claude-in-chrome__form_input, mcp__claude-in-chrome__read_page",
        "Add screenshot capture on failure",
        "Add console error reading on failure",
        "Test single flow: ./e2e/claude_test_runner.sh test_add_github_repository"
      ],
      "passes": false,
      "acceptance_criteria": [
        "claude_test_runner.sh executes test via Claude",
        "5 test prompt files created",
        "MCP tools invoked correctly",
        "Browser automation works",
        "Screenshots captured on failure"
      ]
    },
    {
      "id": "TEST-023",
      "category": "real-e2e",
      "priority": "critical",
      "description": "Create master test runner and update documentation",
      "steps": [
        "Create e2e/run_all_tests.sh that runs all 5 tests in sequence",
        "Script should: Export TEST_MODE=true, Start Docker services, Initialize test-results.json, Loop through all 5 tests, Track PASSED/FAILED counts, Report summary, Exit with failure if any test failed",
        "Make script executable: chmod +x e2e/run_all_tests.sh",
        "Update Makefile with e2e-real target that calls run_all_tests.sh",
        "Update Makefile with seed-test-data target",
        "Update Makefile with test-setup target (seed + docker-up)",
        "Update TESTING.md with 'Running Real E2E Tests' section",
        "Document prerequisites: Docker running, Test data seeded, TEST_MODE enabled",
        "Document commands: make e2e-real, ./e2e/claude_test_runner.sh <test_id>",
        "Document how it works: Claude prompts, MCP tools, real browser interaction",
        "Add troubleshooting section",
        "Test full flow: make test-setup && make e2e-real"
      ],
      "passes": false,
      "acceptance_criteria": [
        "run_all_tests.sh executes all 5 tests",
        "Makefile has e2e-real target",
        "Makefile has seed-test-data target",
        "TESTING.md updated with real E2E guide",
        "Full flow works end-to-end"
      ]
    }
  ]
}
